# Assera Configuration Example
# Copy this file to .env and update values as needed

# ===== Assera API Configuration =====
# API authentication token (REQUIRED - generate a secure random token)
# Example: openssl rand -hex 32
ASSERA_API_TOKEN=change-me-to-a-secure-random-token-at-least-32-chars

# Default LLM model for Ollama
ASSERA_DEFAULT_MODEL=gpt-oss

# Search provider (currently only 'fess' supported)
ASSERA_SEARCH_PROVIDER=fess

# LLM provider (currently only 'ollama' supported)
ASSERA_LLM_PROVIDER=ollama

# ===== Service Endpoints (Internal Docker Network) =====
# Fess search engine
FESS_BASE_URL=http://assera-fess:8080
FESS_TIMEOUT_MS=2000

# Ollama LLM service
OLLAMA_BASE_URL=http://assera-ollama:11434
ASSERA_LLM_TIMEOUT_MS=3000
ASSERA_LLM_TEMPERATURE=0.2
ASSERA_LLM_TOP_P=0.9

# GPU Configuration
# Ollama will automatically use NVIDIA GPU if available (requires nvidia-docker runtime)
# The docker compose configuration includes GPU support by default
# If GPU is not available, Ollama will automatically fall back to CPU
# To check GPU status: make gpu-check
# Prerequisites for GPU:
#   - NVIDIA GPU with recent drivers
#   - nvidia-docker2 or NVIDIA Container Toolkit installed
#   - Docker Compose v2.x or later

# ===== Request Configuration =====
# Total request timeout budget (ms)
REQ_TIMEOUT_MS=5000

# Rate limiting
ASSERA_RATE_LIMIT_PER_MINUTE=60

# ===== CORS Configuration =====
# Allowed origins for API access (comma-separated for multiple origins)
# Single origin: http://localhost:3000
# Multiple origins: http://localhost:3000,http://localhost:3001,http://example.com
CORS_ORIGINS=http://localhost:3000

# ===== UI Configuration =====
# API base path for Next.js frontend
NEXT_PUBLIC_API_BASE=/api/v1

# ===== Logging =====
LOG_LEVEL=INFO
LOG_PII_MASKING=true
DEBUG=false

# ===== Docker User Configuration =====
# Set UID/GID to match host user for proper file permissions
# Default: 1001 (matches Dockerfile defaults)
ASSERA_UID=1000
ASSERA_GID=1000

# ===== Timezone =====
TZ=Asia/Tokyo
